import os
import glob
import json
import argparse
import pickle
import numpy as np
import torch # Added for GPU check
from tifffile import imread
from cellpose.models import CellposeModel # Added for on-the-fly segmentation

### Clone this repo and set the path: https://github.com/Richard-Beck/imutils ###
import sys
sys.path.insert(0, "/home/4473331/projects/imutils/")
from imutils.curation_controller import CurationController
from imutils.object_classification import ObjectClassifier

def parse_args() -> argparse.Namespace:
    """Parses command-line arguments for the labeling script."""
    parser = argparse.ArgumentParser(description="Interactive object labeling and classification.")
    parser.add_argument("--images_dir", required=True, help="Directory containing the composite images (float32) for display.")
    parser.add_argument("--cpose_inputs_dir", required=True, help="Directory containing the Cellpose input images (2, H, W).")
    parser.add_argument("--output_dir", required=True, help="Directory to save session labels and the classifier model.")
    return parser.parse_args()

def get_base_key(stem: str) -> str:
    """Removes known suffixes from a filename stem to get a base key."""
    suffixes_to_strip = [
        '_composite', 
        '_curated_mask',
        '_cpose_input_mask',
        '_cpose_mask',
        '_cpose_input' # Added this to handle the files generated by your new main script
    ]
    for suffix in suffixes_to_strip:
        if stem.endswith(suffix):
            return stem[:-len(suffix)]
    return stem

def main_labelling():
    """
    Main script to launch the interactive object labeling session.
    """
    args = parse_args()

    # --- Setup Paths ---
    os.makedirs(args.output_dir, exist_ok=True)
    SESSION_LABELS_PATH = os.path.join(args.output_dir, "session_labels.json")
    CLASSIFIER_PATH = os.path.join(args.output_dir, "object_classifier.pkl")

    # --- Initialize Cellpose (Once, before the loop) ---
    print("‚è≥ Initializing Cellpose model...")
    # Using the exact syntax you requested:
    model = CellposeModel(gpu=torch.cuda.is_available())

    # --- Load Data ---
    print(f"üîé Finding images in: {args.images_dir}")
    print(f"üîé Finding cellpose inputs in: {args.cpose_inputs_dir}")

    # Create a lookup map for composite images using their base key
    # These are the Float32 (H, W, 3) images for the 2x2 grid display
    image_map = {get_base_key(os.path.splitext(os.path.basename(p))[0]): p for p in glob.glob(os.path.join(args.images_dir, "*.tif"))}
    
    # We iterate over the cellpose inputs now, instead of masks
    cpose_paths = sorted(glob.glob(os.path.join(args.cpose_inputs_dir, "*.tif")))

    if not cpose_paths:
        print(f"‚ùå No cellpose inputs found in '{args.cpose_inputs_dir}'.")
        return

    # Load previous session labels if they exist
    loaded_labels = None
    if os.path.exists(SESSION_LABELS_PATH):
        print(f"üíæ Found existing session labels at {SESSION_LABELS_PATH}. Loading...")
        with open(SESSION_LABELS_PATH, 'r') as f:
            loaded_labels = [{int(k): v for k, v in d.items()} for d in json.load(f)]
        
        # Safety Check: Session labels rely on file order. 
        if len(loaded_labels) != len(cpose_paths):
            print(f"‚ö†Ô∏è  WARNING: Mismatch between number of saved labels ({len(loaded_labels)}) and current files ({len(cpose_paths)}). Labels may not align correctly!")

    # --- Match Images to Inputs, Run Cellpose, and Prepare Data ---
    images_to_load, masks_to_load, labels_to_load, titles_to_load = [], [], [], []
    
    print(f"‚ö° Generating masks for {len(cpose_paths)} images...")
    
    for i, cp_path in enumerate(cpose_paths):
        cp_stem = os.path.splitext(os.path.basename(cp_path))[0]
        base_key = get_base_key(cp_stem)
        
        # Find the corresponding composite image
        image_path = image_map.get(base_key)
        if not image_path:
            print(f"  ‚Üí Warning: No matching composite image found for '{os.path.basename(cp_path)}'. Skipping.")
            continue

        # 1. Load the Cellpose Input (Float32, [2, H, W])
        cpose_input = imread(cp_path)
        
        # 2. Run Cellpose Inference
        # Note: We rely on Cellpose to infer channels or use the 2-channel input as is.
        # Since your inputs are standardized (2, H, W), this usually works well with diameter=None.
        masks, _, _ = model.eval(cpose_input, diameter=None)
        
        # 3. Load the Composite for Display
        images_to_load.append(imread(image_path))
        masks_to_load.append(masks)
        titles_to_load.append(base_key)

        # 4. Load existing labels or create new empty ones
        if loaded_labels and i < len(loaded_labels):
            labels_to_load.append(loaded_labels[i])
        else:
            labels_to_load.append({int(obj_id): 0 for obj_id in np.unique(masks) if obj_id != 0})
            
        if (i + 1) % 10 == 0:
            print(f"  ...processed {i + 1}/{len(cpose_paths)}")

    if not images_to_load:
        print("‚ùå No valid image/input pairs were found. Exiting.")
        return

    # --- Initialize Classifier and Load State ---
    classifier = ObjectClassifier()
    if os.path.exists(CLASSIFIER_PATH):
        try:
            classifier.load_state(CLASSIFIER_PATH)
        except (pickle.UnpicklingError, KeyError, EOFError) as e:
            print(f"‚ö†Ô∏è Could not load classifier state due to error: {e}. Starting with a fresh classifier.")

    # --- Launch Controller ---
    print(f"\nüöÄ Launching interactive session for {len(images_to_load)} images...")
    controller = CurationController(
        images=images_to_load,
        initial_masks=masks_to_load,
        titles=titles_to_load,
        initial_labels=labels_to_load,
        object_classifier=classifier,
        session_path=SESSION_LABELS_PATH,
        classifier_path=CLASSIFIER_PATH
    )
    controller.start()

    print("\nüéâ Labelling session finished!")

if __name__ == "__main__":
    main_labelling()
